{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO3dM7Dc/oUSlVfObdM8AKN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#connect to google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab503ipe5nYz","executionInfo":{"status":"ok","timestamp":1716878100415,"user_tz":-360,"elapsed":27649,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"5766c484-5052-4f1b-fbc5-18071bf7be2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbRTCkzP5iXI"},"outputs":[],"source":["import numpy as np\n","# Load the data from Google Drive\n","y = np.load('/content/gdrive/MyDrive/ECG/arr2D_AF&SR_label.npy')\n","X = np.load('/content/gdrive/MyDrive/ECG/items_AF&SR.npy')"]},{"cell_type":"code","source":["import numpy as np\n","\n","# Assuming arr is your (6428, 5000, 12) shaped array\n","arr = X\n","# Indices to remove from the third dimension\n","indices_to_remove = [2]  # 1st, 3rd, 7th, 8th positions\n","\n","# Remove the specified positions from the third dimension\n","arr = np.delete(arr, indices_to_remove, axis=2)\n","\n","# Now, the shape of arr will be (6428, 5000, 8)\n","print(arr.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciFWESDY5raC","executionInfo":{"status":"ok","timestamp":1716878123642,"user_tz":-360,"elapsed":699,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"538b9c1c-c683-4baf-9f85-1753e26ca63f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3587, 1000, 2)\n"]}]},{"cell_type":"code","source":["print(X.shape)\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hAzUD0J5xlK","executionInfo":{"status":"ok","timestamp":1716878170819,"user_tz":-360,"elapsed":12,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"393bec49-b47d-40d4-89f2-0919d0571cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3587, 1000, 3)\n","[[[ 0.135 -0.125 -0.08 ]\n","  [ 0.135 -0.125 -0.08 ]\n","  [ 0.135 -0.125 -0.08 ]\n","  ...\n","  [-0.125 -0.066 -0.07 ]\n","  [-0.126 -0.063 -0.07 ]\n","  [-0.124 -0.06  -0.07 ]]\n","\n"," [[-0.13  -0.045 -0.03 ]\n","  [-0.13  -0.045 -0.03 ]\n","  [-0.13  -0.045 -0.03 ]\n","  ...\n","  [ 0.003  0.027 -0.02 ]\n","  [ 0.005  0.025 -0.018]\n","  [ 0.005  0.024 -0.015]]\n","\n"," [[-0.47  -0.43  -0.72 ]\n","  [-0.47  -0.43  -0.72 ]\n","  [-0.47  -0.43  -0.72 ]\n","  ...\n","  [-0.064  0.111  0.471]\n","  [-0.075  0.11   0.467]\n","  [-0.081  0.11   0.458]]\n","\n"," ...\n","\n"," [[ 0.025 -0.065  0.06 ]\n","  [ 0.025 -0.065  0.06 ]\n","  [ 0.025 -0.065  0.06 ]\n","  ...\n","  [-0.012 -0.035 -0.018]\n","  [-0.018 -0.006 -0.016]\n","  [-0.02   0.013 -0.021]]\n","\n"," [[ 0.15   0.15   0.02 ]\n","  [ 0.15   0.15   0.02 ]\n","  [ 0.15   0.15   0.02 ]\n","  ...\n","  [ 0.121  0.05   0.063]\n","  [ 0.146  0.049  0.067]\n","  [ 0.166  0.052  0.071]]\n","\n"," [[ 0.015  0.095 -0.005]\n","  [ 0.015  0.095 -0.005]\n","  [ 0.015  0.095 -0.005]\n","  ...\n","  [-0.102  0.113 -0.13 ]\n","  [-0.099  0.124 -0.129]\n","  [-0.1    0.125 -0.124]]]\n"]}]},{"cell_type":"code","source":["# Preprocessing\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n","\n","print(X_scaled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JpiwfED51Ca","executionInfo":{"status":"ok","timestamp":1716878370655,"user_tz":-360,"elapsed":731,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"75a8e6ee-196f-4253-994f-76118938d5b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[ 0.80705828 -0.4588596  -0.25228113]\n","  [ 0.80705828 -0.4588596  -0.25228113]\n","  [ 0.80705828 -0.4588596  -0.25228113]\n","  ...\n","  [-0.71186622 -0.24757386 -0.22215566]\n","  [-0.71770824 -0.23683052 -0.22215566]\n","  [-0.7060242  -0.22608717 -0.22215566]]\n","\n"," [[-0.7410763  -0.17237046 -0.10165378]\n","  [-0.7410763  -0.17237046 -0.10165378]\n","  [-0.7410763  -0.17237046 -0.10165378]\n","  ...\n","  [ 0.035912    0.08546976 -0.07152831]\n","  [ 0.04759603  0.07830753 -0.06550321]\n","  [ 0.04759603  0.07472642 -0.05646557]]\n","\n"," [[-2.72736219 -1.55109943 -2.18031125]\n","  [-2.72736219 -1.55109943 -2.18031125]\n","  [-2.72736219 -1.55109943 -2.18031125]\n","  ...\n","  [-0.35550316  0.38628336  1.4076323 ]\n","  [-0.41976535  0.38270224  1.39558212]\n","  [-0.45481746  0.38270224  1.36846919]]\n","\n"," ...\n","\n"," [[ 0.16443638 -0.24399274  0.16947546]\n","  [ 0.16443638 -0.24399274  0.16947546]\n","  [ 0.16443638 -0.24399274  0.16947546]\n","  ...\n","  [-0.05171826 -0.13655932 -0.06550321]\n","  [-0.08677037 -0.03270701 -0.05947812]\n","  [-0.0984544   0.03533416 -0.07454085]]\n","\n"," [[ 0.89468854  0.52594681  0.04897358]\n","  [ 0.89468854  0.52594681  0.04897358]\n","  [ 0.89468854  0.52594681  0.04897358]\n","  ...\n","  [ 0.72527004  0.16783539  0.1785131 ]\n","  [ 0.87132047  0.16425428  0.19056329]\n","  [ 0.98816082  0.17499762  0.20261348]]\n","\n"," [[ 0.10601621  0.32898553 -0.0263401 ]\n","  [ 0.10601621  0.32898553 -0.0263401 ]\n","  [ 0.10601621  0.32898553 -0.0263401 ]\n","  ...\n","  [-0.57749982  0.39344559 -0.40290848]\n","  [-0.55997377  0.43283784 -0.39989594]\n","  [-0.56581579  0.43641896 -0.3848332 ]]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Assuming X and Y are your arrays\n","X_s = X_scaled\n","Y_s = y\n","# Generate indices for splitting\n","indices = np.arange(len(Y_s))\n","\n","# Split the indices into train and test sets\n","test_indices = indices[::5]  # Every fifth index\n","train_indices = np.setdiff1d(indices, test_indices)\n","\n","# Split X and Y using the generated indices\n","X_tr = X_s[train_indices]\n","Y_tr = Y_s[train_indices]\n","\n","X_ts = X_s[test_indices]\n","Y_ts = Y_s[test_indices]\n","\n","# Check the shapes\n","print(\"X_train shape:\", X_tr.shape)\n","print(\"Y_train shape:\", Y_tr.shape)\n","print(\"X_test shape:\", X_ts.shape)\n","print(\"Y_test shape:\", Y_ts.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nInk5JDP55ty","executionInfo":{"status":"ok","timestamp":1716878375723,"user_tz":-360,"elapsed":4,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"f4e1f091-7bd9-4d43-9377-74870ca8f6fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (2869, 1000, 3)\n","Y_train shape: (2869, 1)\n","X_test shape: (718, 1000, 3)\n","Y_test shape: (718, 1)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten, Bidirectional\n","\n","# Define model parameters\n","num_classes = 2\n","input_shape = (1000, 3)  # assuming 1000 time steps and 3 features\n","\n","# Reshape the data to fit the CNN input shape\n","X_train_cnn = X_tr.reshape((-1, input_shape[0], input_shape[1]))  # reshape without channel dimension\n","X_test_cnn = X_ts.reshape((-1, input_shape[0], input_shape[1]))\n","\n","# Define CNN-Bi-LSTM model architecture\n","model = Sequential([\n","    Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n","    MaxPooling1D(pool_size=2),\n","    Conv1D(128, kernel_size=3, activation='relu'),\n","    MaxPooling1D(pool_size=2),\n","    Bidirectional(LSTM(64, return_sequences=True)),\n","    Bidirectional(LSTM(32)),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Print model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02d0w_pdIpPD","executionInfo":{"status":"ok","timestamp":1716881919187,"user_tz":-360,"elapsed":1672,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"ae3d5f0a-52a0-41c6-c9fb-c648b0c91dc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_8 (Conv1D)           (None, 998, 64)           640       \n","                                                                 \n"," max_pooling1d_8 (MaxPoolin  (None, 499, 64)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_9 (Conv1D)           (None, 497, 128)          24704     \n","                                                                 \n"," max_pooling1d_9 (MaxPoolin  (None, 248, 128)          0         \n"," g1D)                                                            \n","                                                                 \n"," bidirectional_8 (Bidirecti  (None, 248, 128)          98816     \n"," onal)                                                           \n","                                                                 \n"," bidirectional_9 (Bidirecti  (None, 64)                41216     \n"," onal)                                                           \n","                                                                 \n"," dense_17 (Dense)            (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 165506 (646.51 KB)\n","Trainable params: 165506 (646.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Train the model\n","model.fit(X_train_cnn, Y_tr, epochs=100, batch_size=64, validation_split=0.1)\n","\n","# Evaluate the model on test data\n","loss, accuracy = model.evaluate(X_test_cnn, Y_ts)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"id":"iNX6x2WyIu3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the light LSTM student model\n","def create_student_model(input_shape, num_classes):\n","    model = Sequential([\n","        LSTM(32, return_sequences=True, input_shape=input_shape),\n","        LSTM(32),\n","        Dense(64, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","student_model = create_student_model(input_shape, num_classes)\n","student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","student_model.summary()\n","\n","student_model.fit(X_train_cnn, Y_tr, epochs=100, batch_size=64, validation_split=0.1)\n","\n","# Evaluate the model on test data\n","loss, accuracy = student_model.evaluate(X_ts, Y_ts)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4QFm4tMEo5j","executionInfo":{"status":"ok","timestamp":1716881925319,"user_tz":-360,"elapsed":617,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"c55f329e-839d-4b99-feb9-66f3b09113c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_16 (LSTM)              (None, 1000, 32)          4608      \n","                                                                 \n"," lstm_17 (LSTM)              (None, 32)                8320      \n","                                                                 \n"," dense_18 (Dense)            (None, 64)                2112      \n","                                                                 \n"," dense_19 (Dense)            (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 15170 (59.26 KB)\n","Trainable params: 15170 (59.26 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from keras import Model\n","from keras.losses import KLDivergence\n","\n","# Custom training step for knowledge distillation\n","class DistillationModel(Model):\n","    def __init__(self, student, teacher, alpha=0.1, temperature=3):\n","        super(DistillationModel, self).__init__()\n","        self.student = student\n","        self.teacher = teacher\n","        self.alpha = alpha\n","        self.temperature = temperature\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","\n","    def compile(self, optimizer, metrics):\n","        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","\n","    def train_step(self, data):\n","        x, y = data\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            student_predictions = self.student(x, training=True)\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","            distillation_loss = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions / self.temperature, axis=1)\n","            )\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss * (self.temperature ** 2)\n","\n","        gradients = tape.gradient(loss, self.student.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n","\n","        self.compiled_metrics.update_state(y, student_predictions)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def test_step(self, data):\n","        x, y = data\n","        y_pred = self.student(x, training=False)\n","        loss = self.student_loss_fn(y, y_pred)\n","\n","        self.compiled_metrics.update_state(y, y_pred)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","# Instantiate and compile the distillation model\n","distillation_model = DistillationModel(student=student_model, teacher=model, alpha=0.1, temperature=2)\n","distillation_model.compile(optimizer='adam', metrics=['accuracy'])\n","\n","# Train the student model with knowledge distillation\n","distillation_model.fit(X_train_cnn, Y_tr, epochs=100, batch_size=64, validation_split=0.1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCfWnySlEt6D","executionInfo":{"status":"ok","timestamp":1716883566076,"user_tz":-360,"elapsed":336684,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"a7a8132f-3009-40e1-be5d-f40b59811977"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","41/41 [==============================] - 12s 120ms/step - accuracy: 0.8331 - val_accuracy: 0.7422\n","Epoch 2/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8435 - val_accuracy: 0.7526\n","Epoch 3/100\n","41/41 [==============================] - 3s 81ms/step - accuracy: 0.8389 - val_accuracy: 0.7491\n","Epoch 4/100\n","41/41 [==============================] - 4s 95ms/step - accuracy: 0.7804 - val_accuracy: 0.7317\n","Epoch 5/100\n","41/41 [==============================] - 3s 74ms/step - accuracy: 0.7796 - val_accuracy: 0.7317\n","Epoch 6/100\n","41/41 [==============================] - 3s 74ms/step - accuracy: 0.7730 - val_accuracy: 0.7561\n","Epoch 7/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8187 - val_accuracy: 0.7317\n","Epoch 8/100\n","41/41 [==============================] - 4s 103ms/step - accuracy: 0.8350 - val_accuracy: 0.7387\n","Epoch 9/100\n","41/41 [==============================] - 3s 75ms/step - accuracy: 0.8296 - val_accuracy: 0.7282\n","Epoch 10/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8211 - val_accuracy: 0.7038\n","Epoch 11/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7978 - val_accuracy: 0.6829\n","Epoch 12/100\n","41/41 [==============================] - 4s 91ms/step - accuracy: 0.6782 - val_accuracy: 0.5993\n","Epoch 13/100\n","41/41 [==============================] - 4s 88ms/step - accuracy: 0.6495 - val_accuracy: 0.6341\n","Epoch 14/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.6754 - val_accuracy: 0.6376\n","Epoch 15/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.6855 - val_accuracy: 0.6132\n","Epoch 16/100\n","41/41 [==============================] - 3s 83ms/step - accuracy: 0.6778 - val_accuracy: 0.6307\n","Epoch 17/100\n","41/41 [==============================] - 4s 97ms/step - accuracy: 0.6751 - val_accuracy: 0.6272\n","Epoch 18/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.6844 - val_accuracy: 0.6446\n","Epoch 19/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.6952 - val_accuracy: 0.6725\n","Epoch 20/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7088 - val_accuracy: 0.6655\n","Epoch 21/100\n","41/41 [==============================] - 4s 102ms/step - accuracy: 0.7088 - val_accuracy: 0.6655\n","Epoch 22/100\n","41/41 [==============================] - 3s 76ms/step - accuracy: 0.7192 - val_accuracy: 0.6725\n","Epoch 23/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7239 - val_accuracy: 0.6655\n","Epoch 24/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7289 - val_accuracy: 0.6551\n","Epoch 25/100\n","41/41 [==============================] - 4s 87ms/step - accuracy: 0.7250 - val_accuracy: 0.6585\n","Epoch 26/100\n","41/41 [==============================] - 4s 87ms/step - accuracy: 0.7304 - val_accuracy: 0.6864\n","Epoch 27/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7378 - val_accuracy: 0.6829\n","Epoch 28/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7444 - val_accuracy: 0.6620\n","Epoch 29/100\n","41/41 [==============================] - 3s 78ms/step - accuracy: 0.7378 - val_accuracy: 0.6690\n","Epoch 30/100\n","41/41 [==============================] - 4s 105ms/step - accuracy: 0.7467 - val_accuracy: 0.6969\n","Epoch 31/100\n","41/41 [==============================] - 3s 81ms/step - accuracy: 0.7684 - val_accuracy: 0.6934\n","Epoch 32/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.6797 - val_accuracy: 0.6237\n","Epoch 33/100\n","41/41 [==============================] - 3s 75ms/step - accuracy: 0.6917 - val_accuracy: 0.6760\n","Epoch 34/100\n","41/41 [==============================] - 4s 100ms/step - accuracy: 0.7297 - val_accuracy: 0.6585\n","Epoch 35/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7471 - val_accuracy: 0.6829\n","Epoch 36/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7587 - val_accuracy: 0.6829\n","Epoch 37/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.7637 - val_accuracy: 0.7038\n","Epoch 38/100\n","41/41 [==============================] - 4s 98ms/step - accuracy: 0.7777 - val_accuracy: 0.7108\n","Epoch 39/100\n","41/41 [==============================] - 3s 76ms/step - accuracy: 0.7808 - val_accuracy: 0.7213\n","Epoch 40/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7874 - val_accuracy: 0.6969\n","Epoch 41/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7746 - val_accuracy: 0.6969\n","Epoch 42/100\n","41/41 [==============================] - 4s 88ms/step - accuracy: 0.7401 - val_accuracy: 0.7003\n","Epoch 43/100\n","41/41 [==============================] - 4s 86ms/step - accuracy: 0.7730 - val_accuracy: 0.7178\n","Epoch 44/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7843 - val_accuracy: 0.7038\n","Epoch 45/100\n","41/41 [==============================] - 3s 71ms/step - accuracy: 0.7765 - val_accuracy: 0.7143\n","Epoch 46/100\n","41/41 [==============================] - 3s 77ms/step - accuracy: 0.7928 - val_accuracy: 0.7108\n","Epoch 47/100\n","41/41 [==============================] - 4s 98ms/step - accuracy: 0.8106 - val_accuracy: 0.7108\n","Epoch 48/100\n","41/41 [==============================] - 3s 71ms/step - accuracy: 0.8091 - val_accuracy: 0.7108\n","Epoch 49/100\n","41/41 [==============================] - 3s 70ms/step - accuracy: 0.8110 - val_accuracy: 0.7143\n","Epoch 50/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8203 - val_accuracy: 0.7073\n","Epoch 51/100\n","41/41 [==============================] - 4s 92ms/step - accuracy: 0.8242 - val_accuracy: 0.7282\n","Epoch 52/100\n","41/41 [==============================] - 3s 81ms/step - accuracy: 0.8122 - val_accuracy: 0.7108\n","Epoch 53/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8296 - val_accuracy: 0.7387\n","Epoch 54/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8327 - val_accuracy: 0.7108\n","Epoch 55/100\n","41/41 [==============================] - 3s 86ms/step - accuracy: 0.8331 - val_accuracy: 0.7387\n","Epoch 56/100\n","41/41 [==============================] - 4s 90ms/step - accuracy: 0.8300 - val_accuracy: 0.7178\n","Epoch 57/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8335 - val_accuracy: 0.7282\n","Epoch 58/100\n","41/41 [==============================] - 3s 74ms/step - accuracy: 0.8350 - val_accuracy: 0.7387\n","Epoch 59/100\n","41/41 [==============================] - 3s 78ms/step - accuracy: 0.8366 - val_accuracy: 0.7352\n","Epoch 60/100\n","41/41 [==============================] - 4s 104ms/step - accuracy: 0.8369 - val_accuracy: 0.7282\n","Epoch 61/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8505 - val_accuracy: 0.7282\n","Epoch 62/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8486 - val_accuracy: 0.7491\n","Epoch 63/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8451 - val_accuracy: 0.7282\n","Epoch 64/100\n","41/41 [==============================] - 4s 99ms/step - accuracy: 0.8517 - val_accuracy: 0.7317\n","Epoch 65/100\n","41/41 [==============================] - 3s 76ms/step - accuracy: 0.8679 - val_accuracy: 0.7422\n","Epoch 66/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8524 - val_accuracy: 0.7247\n","Epoch 67/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8466 - val_accuracy: 0.7526\n","Epoch 68/100\n","41/41 [==============================] - 3s 86ms/step - accuracy: 0.8563 - val_accuracy: 0.7213\n","Epoch 69/100\n","41/41 [==============================] - 4s 88ms/step - accuracy: 0.8404 - val_accuracy: 0.6551\n","Epoch 70/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8056 - val_accuracy: 0.7213\n","Epoch 71/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8288 - val_accuracy: 0.7317\n","Epoch 72/100\n","41/41 [==============================] - 3s 75ms/step - accuracy: 0.8366 - val_accuracy: 0.7456\n","Epoch 73/100\n","41/41 [==============================] - 4s 100ms/step - accuracy: 0.8493 - val_accuracy: 0.7247\n","Epoch 74/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8644 - val_accuracy: 0.7456\n","Epoch 75/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8528 - val_accuracy: 0.7387\n","Epoch 76/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8586 - val_accuracy: 0.7526\n","Epoch 77/100\n","41/41 [==============================] - 4s 96ms/step - accuracy: 0.8613 - val_accuracy: 0.7317\n","Epoch 78/100\n","41/41 [==============================] - 3s 81ms/step - accuracy: 0.8385 - val_accuracy: 0.7422\n","Epoch 79/100\n","41/41 [==============================] - 3s 75ms/step - accuracy: 0.8505 - val_accuracy: 0.7352\n","Epoch 80/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8664 - val_accuracy: 0.7352\n","Epoch 81/100\n","41/41 [==============================] - 4s 86ms/step - accuracy: 0.8633 - val_accuracy: 0.7317\n","Epoch 82/100\n","41/41 [==============================] - 4s 88ms/step - accuracy: 0.8737 - val_accuracy: 0.7491\n","Epoch 83/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8753 - val_accuracy: 0.7387\n","Epoch 84/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8799 - val_accuracy: 0.7317\n","Epoch 85/100\n","41/41 [==============================] - 3s 76ms/step - accuracy: 0.8776 - val_accuracy: 0.7352\n","Epoch 86/100\n","41/41 [==============================] - 4s 99ms/step - accuracy: 0.8540 - val_accuracy: 0.7282\n","Epoch 87/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8776 - val_accuracy: 0.7352\n","Epoch 88/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8292 - val_accuracy: 0.6202\n","Epoch 89/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.7599 - val_accuracy: 0.7456\n","Epoch 90/100\n","41/41 [==============================] - 4s 97ms/step - accuracy: 0.8590 - val_accuracy: 0.7491\n","Epoch 91/100\n","41/41 [==============================] - 3s 78ms/step - accuracy: 0.8571 - val_accuracy: 0.7491\n","Epoch 92/100\n","41/41 [==============================] - 3s 72ms/step - accuracy: 0.8644 - val_accuracy: 0.7247\n","Epoch 93/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8869 - val_accuracy: 0.7213\n","Epoch 94/100\n","41/41 [==============================] - 4s 87ms/step - accuracy: 0.8734 - val_accuracy: 0.7178\n","Epoch 95/100\n","41/41 [==============================] - 4s 86ms/step - accuracy: 0.8745 - val_accuracy: 0.7143\n","Epoch 96/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8892 - val_accuracy: 0.7526\n","Epoch 97/100\n","41/41 [==============================] - 3s 71ms/step - accuracy: 0.8373 - val_accuracy: 0.6655\n","Epoch 98/100\n","41/41 [==============================] - 3s 77ms/step - accuracy: 0.8207 - val_accuracy: 0.6934\n","Epoch 99/100\n","41/41 [==============================] - 4s 98ms/step - accuracy: 0.8203 - val_accuracy: 0.7352\n","Epoch 100/100\n","41/41 [==============================] - 3s 73ms/step - accuracy: 0.8447 - val_accuracy: 0.7282\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7dc0465bbdc0>"]},"metadata":{},"execution_count":42}]}]}